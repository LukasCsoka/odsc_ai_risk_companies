{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "#  Bias in Data\n",
        "\n",
        "The code that Iâ€™m providing has been built mainly upon the following sources:\n",
        " \n",
        "- https:\/\/fairmlbook.org\/\n",
        "- https:\/\/dalex.drwhy.ai\/python-dalex-fairness.html\n",
        "- https:\/\/dalex.drwhy.ai\/python\/\n",
        "- https:\/\/www.kdnuggets.com\/2020\/12\/machine-learning-model-fair.html\n",
        " \n",
        "Unverified black box model is the path to the failure. Opaqueness leads to distrust. Distrust leads to ignoration. Ignoration leads to rejection.\n",
        "\n",
        "The dalex package xrays any model and helps to explore and explain its behaviour, helps to understand how complex models are working. The main [Explainer](https:\/\/dalex.drwhy.ai\/python\/api\/#dalex.Explainer) object creates a wrapper around a predictive model. Wrapped models may then be explored and compared with a collection of model-level and predict-level explanations. Moreover, there are fairness methods and interactive exploration dashboards available to the user.\n",
        "\n",
        "The philosophy behind dalex explanations is described in the [Explanatory Model Analysis e-book](https:\/\/ema.drwhy.ai\/)."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# basic imports\n",
        "import dalex as dx\n",
        "import numpy as np\n",
        "\n",
        "# import scikit-learn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "To showcase the problem of fairness in AI, we will be using the German Credit Data dataset to assign risk for each credit-seeker.\n",
        "Information about this dataset can be found here: https:\/\/archive.ics.uci.edu\/ml\/datasets\/statlog+(german+credit+data)\n",
        "\n",
        "We will at first create a very simple ML model (decision tree) for the data. Additionally, we will use create random forest and logistic regression, but thes two models will be used later.\n",
        "\n",
        "It is very important to avoid any bias, when a person applies for loan in bank, as nobody would want to be negatively affected, as well if the bank does not have reliable model, the bank can lose part of business or provide loans to people, that would not receive loans by unbiased models. \n",
        "\n",
        "The data we use for modeling is in the major part a reflection of the world it derives from. And as the world can be biased, so data and therefore model will likely reflect that. "
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# load credit data\n",
        "data = dx.datasets.load_german()\n",
        "\n",
        "# risk is the target variable\n",
        "features = data.drop(columns='risk')\n",
        "labels = data.risk\n",
        "\n",
        "# select few categorical and numerical features\n",
        "categorical_features = ['sex', 'job', 'housing', 'saving_accounts', \"checking_account\", 'purpose']\n",
        "numeric_features = ['credit_amount', 'age']\n",
        "\n",
        "# create one hot encoder for categorical variables as transformer\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# scale numerical features as transformer\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "        ('num', numeric_transformer, numeric_features)])\n",
        "\n",
        "\n",
        "# create a pipeline, containing the above transformer and decision tree\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(max_depth=7, random_state=42))\n",
        "])\n",
        "\n",
        "# train decision tree on this data\n",
        "clf.fit(features, labels)\n",
        "\n",
        "# train also random forest - it will be used later\n",
        "clf_forest = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', RandomForestClassifier(random_state=42, max_depth=5))]).fit(features,labels)\n",
        "\n",
        "# trian also logistic regression - it will be used later\n",
        "clf_logreg = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', LogisticRegression(random_state=42))]).fit(features,labels)\n",
        "\n",
        "# plot confusion matrix of decision tree\n",
        "plot_confusion_matrix(clf, features, labels)"
      ],
      "execution_count":29,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7efd71f93c40>"
            ],
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              "width":0,
              "height":0
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We create an Explainer object to showcase dalex functionalities. Then we look at the overal performance of our model. Even through its simple, it is not bad. At first, we will use only decision tree."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "exp = dx.Explainer(clf, features, labels)\n",
        "exp.model_performance().result"
      ],
      "execution_count":32,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Preparation of a new explainer is initiated\n",
            "\n",
            "  -> data              : 1000 rows 9 cols\n",
            "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
            "  -> target variable   : 1000 values\n",
            "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
            "  -> label             : Not specified, model's class short name will be used. (default)\n",
            "  -> predict function  : <function yhat_proba_default at 0x7efd931253a0> will be used (default)\n",
            "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
            "  -> predicted values  : min = 0.0, mean = 0.7, max = 1.0\n",
            "  -> model type        : classification will be used (default)\n",
            "  -> residual function : difference between y and yhat (default)\n",
            "  -> residuals         : min = -0.944, mean = 8.88e-19, max = 0.923\n",
            "  -> model_info        : package sklearn\n",
            "\n",
            "A new explainer has been created!\n"
          ],
          "output_type":"stream"
        },
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>recall<\/th>\n",
              "      <th>precision<\/th>\n",
              "      <th>f1<\/th>\n",
              "      <th>accuracy<\/th>\n",
              "      <th>auc<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier<\/th>\n",
              "      <td>0.941429<\/td>\n",
              "      <td>0.829975<\/td>\n",
              "      <td>0.882195<\/td>\n",
              "      <td>0.824<\/td>\n",
              "      <td>0.883371<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "To check if the model is biased, we will use the fairness module from dalex. Checking if the model is fair should be straightforward. Apart from the dx.Explainer, we will need 2 parameters:\n",
        "\n",
        "- protected - array-like of subgroups values that denote a sensitive attribute (protected variable) like sex, nationality etc. The fairness metrics will be calculated for each of those subgroups and compared.\n",
        "- privileged - a string representing one of the subgroups. It should be the one suspected of the most privilege.\n",
        "\n",
        "The idea here is that ratios between scores of privileged and unprivileged metrics should be close to 1. The closer the more fair the model is. But to relax this criterion a little bit, it can be written more thoughtfully:\n",
        "\n",
        "$\\forall_{i \\varepsilon \\{a,b,...,z\\}}  \\epsilon  \\frac{metrix_i}{metric_{privileged}} < \\frac{1}{\\epsilon}$\n",
        "\n",
        "where the epsilon is a value between 0 and 1. It should be a minimum acceptable ratio. On default, it is 0.8, which adheres to [four-fifths rule (80% rule)](https:\/\/www.hirevue.com\/blog\/hiring\/what-is-adverse-impact-and-why-measuring-it-matters) commonly used. Of course, a user may change this value to their needs."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# array with values like male_old, female_young, etc.\n",
        "protected = data.sex + '_' + np.where(data.age < 25, 'young', 'old')\n",
        "\n",
        "privileged = 'male_old'  # we assume, that older males are prviliged compared to young females, lets thest this hypothesis\n",
        "\n",
        "fobject = exp.model_fairness(protected = protected, privileged = privileged)\n",
        "fobject.fairness_check(epsilon = 0.8)"
      ],
      "execution_count":36,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Bias detected in 3 metrics: TPR, FPR, STP\n",
            "\n",
            "Conclusion: your model is not fair because 2 or more criteria exceeded acceptable limits set by epsilon.\n",
            "\n",
            "Ratios of metrics, based on 'male_old'. Parameter 'epsilon' was set to 0.8 and therefore metrics should be within (0.8, 1.25)\n",
            "                   TPR       ACC       PPV       FPR       STP\n",
            "female_old    1.019771  0.981020  0.952719  1.022822  0.986811\n",
            "female_young  0.736733  0.832740  0.893617  0.634855  0.642686\n",
            "male_young    0.884495  0.931198  0.957447  0.663900  0.774580\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "This model should not be called fair. Generally, each metric should be between (epsilon, 1\/epsilon). Metrics are calculated for each subgroup, and then their scores are divided by the score of the privileged subgroup. That is why we omit male_old in this method. When at least 2 metrics have scores ratio outside of the epsilon range, dalex declared this model unfair. In our case it cannot be decided automatically but the bias is visible and FPR (False Positive Rate) is especially important in case of risk assigning, so let's call our model unfair.\n",
        "\n",
        "The bias was spotted in metric FPR, which is the False Positive Rate. The output above suggests that the model cannot be automatically approved (like said in the output above). So it is up to the user to decide. In my opinion, it is not a fair model. Lower FPR means that the privileged subgroup is getting False Positives more frequently than the unprivileged."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Let's check more metrics\n",
        "\n",
        "We get the information about bias, the conclusion, and metrics ratio raw DataFrame. There are metrics TPR (True Positive Rate), ACC (Accuracy), PPV (Positive Predictive Value), FPR (False Positive Rate), STP(Statistical parity). The metrics are derived from a confusion matrix for each unprivileged subgroup and then divided by metric values based on the privileged subgroup. \n",
        "\n",
        "The result attribute is metric_scores where each row is divided by row indexed with privileged (in this case male_old)."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "fobject.result # to see all scaled metric values"
      ],
      "execution_count":37,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>TPR<\/th>\n",
              "      <th>TNR<\/th>\n",
              "      <th>PPV<\/th>\n",
              "      <th>NPV<\/th>\n",
              "      <th>FNR<\/th>\n",
              "      <th>FPR<\/th>\n",
              "      <th>FDR<\/th>\n",
              "      <th>FOR<\/th>\n",
              "      <th>ACC<\/th>\n",
              "      <th>STP<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>female_old<\/th>\n",
              "      <td>1.019771<\/td>\n",
              "      <td>0.978764<\/td>\n",
              "      <td>0.952719<\/td>\n",
              "      <td>1.118501<\/td>\n",
              "      <td>0.512821<\/td>\n",
              "      <td>1.022822<\/td>\n",
              "      <td>1.259740<\/td>\n",
              "      <td>0.433526<\/td>\n",
              "      <td>0.981020<\/td>\n",
              "      <td>0.986811<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>female_young<\/th>\n",
              "      <td>0.736733<\/td>\n",
              "      <td>1.339768<\/td>\n",
              "      <td>0.893617<\/td>\n",
              "      <td>0.775091<\/td>\n",
              "      <td>7.487179<\/td>\n",
              "      <td>0.634855<\/td>\n",
              "      <td>1.584416<\/td>\n",
              "      <td>2.075145<\/td>\n",
              "      <td>0.832740<\/td>\n",
              "      <td>0.642686<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>male_old<\/th>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "      <td>1.000000<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>male_young<\/th>\n",
              "      <td>0.884495<\/td>\n",
              "      <td>1.312741<\/td>\n",
              "      <td>0.957447<\/td>\n",
              "      <td>0.893591<\/td>\n",
              "      <td>3.846154<\/td>\n",
              "      <td>0.663900<\/td>\n",
              "      <td>1.233766<\/td>\n",
              "      <td>1.508671<\/td>\n",
              "      <td>0.931198<\/td>\n",
              "      <td>0.774580<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "fobject.metric_scores # or unscaled ones"
      ],
      "execution_count":38,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>TPR<\/th>\n",
              "      <th>TNR<\/th>\n",
              "      <th>PPV<\/th>\n",
              "      <th>NPV<\/th>\n",
              "      <th>FNR<\/th>\n",
              "      <th>FPR<\/th>\n",
              "      <th>FDR<\/th>\n",
              "      <th>FOR<\/th>\n",
              "      <th>ACC<\/th>\n",
              "      <th>STP<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>female_old<\/th>\n",
              "      <td>0.980<\/td>\n",
              "      <td>0.507<\/td>\n",
              "      <td>0.806<\/td>\n",
              "      <td>0.925<\/td>\n",
              "      <td>0.020<\/td>\n",
              "      <td>0.493<\/td>\n",
              "      <td>0.194<\/td>\n",
              "      <td>0.075<\/td>\n",
              "      <td>0.827<\/td>\n",
              "      <td>0.823<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>female_young<\/th>\n",
              "      <td>0.708<\/td>\n",
              "      <td>0.694<\/td>\n",
              "      <td>0.756<\/td>\n",
              "      <td>0.641<\/td>\n",
              "      <td>0.292<\/td>\n",
              "      <td>0.306<\/td>\n",
              "      <td>0.244<\/td>\n",
              "      <td>0.359<\/td>\n",
              "      <td>0.702<\/td>\n",
              "      <td>0.536<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>male_old<\/th>\n",
              "      <td>0.961<\/td>\n",
              "      <td>0.518<\/td>\n",
              "      <td>0.846<\/td>\n",
              "      <td>0.827<\/td>\n",
              "      <td>0.039<\/td>\n",
              "      <td>0.482<\/td>\n",
              "      <td>0.154<\/td>\n",
              "      <td>0.173<\/td>\n",
              "      <td>0.843<\/td>\n",
              "      <td>0.834<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>male_young<\/th>\n",
              "      <td>0.850<\/td>\n",
              "      <td>0.680<\/td>\n",
              "      <td>0.810<\/td>\n",
              "      <td>0.739<\/td>\n",
              "      <td>0.150<\/td>\n",
              "      <td>0.320<\/td>\n",
              "      <td>0.190<\/td>\n",
              "      <td>0.261<\/td>\n",
              "      <td>0.785<\/td>\n",
              "      <td>0.646<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Let's look at some plot (dalex uses plotly)\n",
        "\n",
        "There are two bias detection plots available (however, there are more ways to visualize bias in the package)\n",
        "\n",
        "- fairness_checkâ€” visualization of fairness_check() method\n",
        "- metric_scoresâ€” visualization of metric_scores attribute which is raw scores of metrics.\n",
        "\n",
        "For fairness_check, if a bar reaches the red field, it means that for this metric model is exceeding the (epsilon, 1\/epsilon) range. In this case the DecisionTreeClassifier has one NaN. In this case appropriate message is given (it can be disabled with verbose=False).\n",
        "\n",
        "For metric_scores, vertical lines showcase the score of the privileged subgroup. Points closer to the line indicate less bias in the model."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "fobject.plot()"
      ],
      "execution_count":39,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "fobject.plot(type = 'metric_scores')"
      ],
      "execution_count":40,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Multiple models\n",
        "\n",
        "Let's now use also random forest and logistic regression results."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# create Explainer objects \n",
        "exp_forest  = dx.Explainer(clf_forest, features, labels, verbose = False)\n",
        "exp_logreg  = dx.Explainer(clf_logreg, features, labels, verbose = False)\n",
        "\n",
        "# create fairness explanations\n",
        "fobject_forest = exp_forest.model_fairness(protected, privileged)\n",
        "fobject_logreg = exp_logreg.model_fairness(protected, privileged)\n",
        "\n",
        "# fairness check\n",
        "fobject_forest.fairness_check(epsilon = 0.8)\n",
        "fobject_logreg.fairness_check(epsilon = 0.8)"
      ],
      "execution_count":42,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Bias detected in 2 metrics: FPR, STP\n",
            "\n",
            "Conclusion: your model is not fair because 2 or more criteria exceeded acceptable limits set by epsilon.\n",
            "\n",
            "Ratios of metrics, based on 'male_old'. Parameter 'epsilon' was set to 0.8 and therefore metrics should be within (0.8, 1.25)\n",
            "                   TPR       ACC       PPV       FPR       STP\n",
            "female_old    0.990900  0.974684  0.962963  0.884058  0.949353\n",
            "female_young  0.884732  0.903797  0.893997  0.658762  0.769397\n",
            "male_young    0.985844  0.915190  0.888889  0.895916  0.928879\n",
            "Bias detected in 3 metrics: TPR, FPR, STP\n",
            "\n",
            "Conclusion: your model is not fair because 2 or more criteria exceeded acceptable limits set by epsilon.\n",
            "\n",
            "Ratios of metrics, based on 'male_old'. Parameter 'epsilon' was set to 0.8 and therefore metrics should be within (0.8, 1.25)\n",
            "                   TPR       ACC       PPV       FPR       STP\n",
            "female_old    0.917109  0.944954  0.971831  0.788752  0.870056\n",
            "female_young  0.774708  0.889908  0.914213  0.533608  0.658757\n",
            "male_young    0.929862  0.887287  0.878361  0.877915  0.887006\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "fobject.plot(objects=[fobject_forest, fobject_logreg])"
      ],
      "execution_count":43,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "fobject.plot(objects=[fobject_forest, fobject_logreg], type = \"radar\")"
      ],
      "execution_count":44,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Metrics"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "\n",
        "| Metric | Formula | Full name | fairness names while checking among subgroups |\n",
        "| ----------- | ----------- | ----------- | ----------- |\n",
        "| TPR | $\\frac{TP}{TP+FN}$ | true positive rate | equal opportunity |\n",
        "| TNR | $\\frac{TN}{TP+FP}$ | true negative rate |  |\n",
        "| PPV | $\\frac{TP}{TP+FP}$ | positive predictive value |  |\n",
        "| NPV | $\\frac{TN}{TN+FN}$ | negative predictive value |  |\n",
        "| FNR | $\\frac{FP}{FN+TP}$ | false negative rate\t |  |\n",
        "| FPR | $\\frac{FN}{FP+TN}$ | false positive rate\t | predictive equality |\n",
        "| FDR | $\\frac{FP}{FP+TP}$ | false discovery rate |  |\n",
        "| FOR | $\\frac{FN}{FN+TN}$ | false ommision rate |  |\n",
        "| TS |  $\\frac{TP}{TP+FN+FP}$ | threat score |  |\n",
        "| STP | $\\frac{TP+FP}{TP+FN+FP+TN}$ | statistical parity | statistical parity |\n",
        "| ACC | $\\frac{TP+TN}{TP+FN+FP+TN}$ | accuracy | overall accuracy equality |\n",
        "| F1 | $2\\cdot \\frac{PPV*TPR}{PPV-TPR}$ | f1 score |  |"
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}