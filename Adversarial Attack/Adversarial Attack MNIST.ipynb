{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "#  Adversarial Attack on MNIST Using JAX\n",
        "\n",
        "The code that Iâ€™m providing has been built upon the following sources:\n",
        "\n",
        "- https:\/\/towardsdatascience.com\/creating-adversarial-examples-with-jax-from-the-scratch-bf267757f672\n",
        "- https:\/\/github.com\/cleverhans-lab\/cleverhans\n",
        "- https:\/\/www.tensorflow.org\/tutorials\/generative\/adversarial_fgsm\n",
        "\n",
        "CleverHans is a Python library to benchmark machine learning systems' vulnerability to adversarial examples. I highly recommend checking this library. You can learn more about such vulnerabilities on the accompanying blog.\n",
        "\n",
        "- Adversarial examples: http:\/\/karpathy.github.io\/2015\/03\/30\/breaking-convnets\/\n",
        "- Adversarial blog: http:\/\/www.cleverhans.io\/"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## This section contains imports and definitions of parameters."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# basic imports\n",
        "import array\n",
        "import itertools\n",
        "import numpy\n",
        "import numpy.random as npr\n",
        "import os\n",
        "import struct\n",
        "\n",
        "# to download MNIST, unzip and load into memory\n",
        "import gzip\n",
        "from os import path\n",
        "import urllib.request\n",
        "\n",
        "# JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research.\n",
        "# Excellent blog to learn more about JAX: https:\/\/colinraffel.com\/blog\/you-don-t-know-jax.html\n",
        "import jax.numpy as np\n",
        "from jax.api import grad\n",
        "from jax.scipy.special import logsumexp\n",
        "from jax import random\n",
        "from jax.experimental import optimizers\n",
        "from jax.experimental import stax\n",
        "\n",
        "# to visualize results \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# parameters definition\n",
        "DATA_FOLDER = \"\/tmp\/\"\n",
        "BASE_URL = \"https:\/\/storage.googleapis.com\/cvdf-datasets\/mnist\/\""
      ],
      "attachments":{
        
      },
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## This section downloads, unzips and lods MNIST data.\n",
        "If you do not know MNIST, check this source: https:\/\/en.wikipedia.org\/wiki\/MNIST_database"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def _download_url(url, filename):\n",
        "  \"\"\"Download a url to a file in the temp directory.\"\"\"\n",
        "  if not path.exists(DATA_FOLDER):\n",
        "    os.makedirs(DATA_FOLDER)\n",
        "  out_file = path.join(DATA_FOLDER, filename)\n",
        "  if not path.isfile(out_file):\n",
        "    urllib.request.urlretrieve(url, out_file)\n",
        "    print(\"downloaded {} to {}\".format(url, DATA_FOLDER))\n",
        "\n",
        "\n",
        "def _partial_flatten(x):\n",
        "  \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
        "  return numpy.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "\n",
        "def _one_hot(x, k, dtype=numpy.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return numpy.array(x[:, None] == numpy.arange(k), dtype)\n",
        "\n",
        "\n",
        "def mnist_raw():\n",
        "  \"\"\"Download and parse the MNIST dataset.\"\"\"\n",
        "  \n",
        "  def parse_labels(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _ = struct.unpack(\">II\", fh.read(8))\n",
        "      return numpy.array(array.array(\"B\", fh.read()), dtype=numpy.uint8)\n",
        "\n",
        "  def parse_images(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "      return numpy.array(array.array(\"B\", fh.read()),\n",
        "                      dtype=numpy.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "  for filename in [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "                   \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]:\n",
        "    _download_url(BASE_URL + filename, filename)\n",
        "\n",
        "  train_images = parse_images(path.join(DATA_FOLDER, \"train-images-idx3-ubyte.gz\"))\n",
        "  train_labels = parse_labels(path.join(DATA_FOLDER, \"train-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "  return train_images, train_labels#, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist():\n",
        "  \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
        "  train_images, train_labels = mnist_raw()\n",
        "\n",
        "  train_images = _partial_flatten(train_images) \/ numpy.float32(255.)\n",
        "  train_labels = _one_hot(train_labels, 10)\n",
        "\n",
        "  return train_images, train_labels\n",
        "\n",
        "\n",
        "def shape_as_image(images, labels, dummy_dim=False):\n",
        "  target_shape = (-1, 1, 28, 28, 1) if dummy_dim else (-1, 28, 28, 1)\n",
        "  return np.reshape(images, target_shape), labels\n",
        "\n",
        "\n",
        "train_images, train_labels = mnist()  # here starts the execution\n",
        "num_train = train_images.shape[0]"
      ],
      "attachments":{
        
      },
      "execution_count":2,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "downloaded https:\/\/storage.googleapis.com\/cvdf-datasets\/mnist\/train-images-idx3-ubyte.gz to \/tmp\/\n",
            "downloaded https:\/\/storage.googleapis.com\/cvdf-datasets\/mnist\/train-labels-idx1-ubyte.gz to \/tmp\/\n",
            "downloaded https:\/\/storage.googleapis.com\/cvdf-datasets\/mnist\/t10k-images-idx3-ubyte.gz to \/tmp\/\n",
            "downloaded https:\/\/storage.googleapis.com\/cvdf-datasets\/mnist\/t10k-labels-idx1-ubyte.gz to \/tmp\/\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## We will create a simple convolutional neural network for predicting classes of handwritten digits. We will adversarially attack this neural network by using fast gradient sign method (FGSM).\n",
        "\n",
        "Very good blog about this method is available here: https:\/\/towardsdatascience.com\/perhaps-the-simplest-introduction-of-adversarial-examples-ever-c0839a759b8d\n",
        "\n",
        "FGSM adds noise (not random noise) whose direction is the same as the gradient of the cost function with respect to the data. The noise is scaled epsilon, which is usually constrained to be a small number via max norm. The magnitude of gradient does not matter in this formula, but the direction (+\/-) matters.\n",
        "\n",
        "$adv\\_x = x + \\epsilon*\\text{sign}(\\nabla_xJ(\\theta, x, y))$\n",
        "\n",
        "where\n",
        "\n",
        "- adv_x : Adversarial image.\n",
        "- x : Original input image.\n",
        "- y : Original input label.\n",
        "- $\\epsilon$ : Multiplier to ensure the perturbations are small.\n",
        "- $\\theta$ : Model parameters.\n",
        "- $J$ : Loss.\n",
        "\n",
        "The gradients are taken with respect to the input image. This is done because the objective is to create an image that maximises the loss. A method to accomplish this is to find how much each pixel in the image contributes to the loss value. After that, we will add a perturbation accordingly. \n",
        "\n",
        "This is fast because it is easy to find how each input pixel contributes to the loss by using the chain rule and finding the required gradients. Hence, the gradients are taken with respect to the image. In addition, since the model is no longer being trained (thus the gradient is not taken with respect to the trainable variables, i.e., the model parameters), and so the model parameters remain constant. The only goal is to fool an already trained model.\n",
        "\n",
        "The explanation above was taken from here: https:\/\/www.tensorflow.org\/tutorials\/generative\/adversarial_fgsm This page also contains an excelent tutorial. The model is MobileNetV2 model, pretrained on ImageNet. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def predict(params, inputs):\n",
        "  \"\"\"We define the function which will compute the output of a fully-connected neural\n",
        "  network by iterating over all of its layers, taking the activations of the input\/previous layer\n",
        "  and applying the tanh activation.\"\"\"\n",
        "  \n",
        "  activations = inputs\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = np.dot(activations, w) + b \n",
        "    activations = np.tanh(outputs)\n",
        "\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = np.dot(activations, final_w) + final_b\n",
        "  return logits - logsumexp(logits, axis=1, keepdims=True)"
      ],
      "attachments":{
        
      },
      "execution_count":3,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## A fully-connected neural network architecture using â€˜staxâ€™ is defined. Stax is experimental sub-library of Jax. Stax is a neural net specification library. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "init_random_params, predict = stax.serial(\n",
        "    stax.Conv(64, (7,7), padding='SAME'),\n",
        "    stax.Relu,\n",
        "    stax.Conv(32, (4, 4), padding='SAME'),\n",
        "    stax.Relu,\n",
        "    stax.MaxPool((3, 3)),\n",
        "    stax.Flatten,\n",
        "    stax.Dense(128),\n",
        "    stax.Relu,\n",
        "    stax.Dense(10),\n",
        ")"
      ],
      "attachments":{
        
      },
      "execution_count":4,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Cross-entropy is a measure of the difference between two probability distributions for a given random variable or set of events. A gentle introduction to cross-entropy are here:\n",
        "\n",
        "- https:\/\/machinelearningmastery.com\/cross-entropy-for-machine-learning\/\n",
        "- https:\/\/medium.com\/data-science-bootcamp\/understand-cross-entropy-loss-in-minutes-9fb263caee9a"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# loss function for calculating predictions and accuracy before pertubation\n",
        "def loss(params, batch, test=0):\n",
        "  inputs, targets = batch\n",
        "  logits = predict(params, inputs)\n",
        "  preds  = stax.logsoftmax(logits)\n",
        "\n",
        "  if test == 1:  # only if we are testing\n",
        "    print('Prediction vector before softmax')\n",
        "    print(logits)\n",
        "    print(\"____________________________________________________________________________________\")\n",
        "    print('Prediction vector after softmax')\n",
        "    print(preds)\n",
        "    print(\"____________________________________________________________________________________\")\n",
        "  return -(1\/(preds.shape[0]))*np.sum(targets*preds)\n",
        "\n",
        "# loss function for calculating gradients of loss w.r.t. input image\n",
        "def lo(batch,params):\n",
        "  inputs, targets = batch\n",
        "  logits = predict(params, inputs)\n",
        "  preds  = stax.logsoftmax(logits)\n",
        "  return -(1\/(preds.shape[0]))*np.sum(targets*preds)"
      ],
      "attachments":{
        
      },
      "execution_count":11,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# The following function defines the accuracy of our model.\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class), target_class, predicted_class"
      ],
      "attachments":{
        
      },
      "execution_count":10,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# We define a Python generator for our dataset. It outputs one batch of n training examples at a time."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "batch_size = 128\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream():\n",
        "  rng = npr.RandomState(0)\n",
        "  while True:\n",
        "    perm = rng.permutation(num_train)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "      yield train_images[batch_idx], train_labels[batch_idx]\n",
        "\n",
        "batches = data_stream()"
      ],
      "attachments":{
        
      },
      "execution_count":12,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Here we construct optimizer Mini-batch gradient descent optimizer.\n",
        "\n",
        "Mini-batch gradient descent finally takes the best from Batch gradient descent and Stochastic gradient descent. Recommended blog about these methods is here: https:\/\/ruder.io\/optimizing-gradient-descent\/\n",
        "\n",
        "opt_init is a pytree representing the initial optimizer state, which includes the initial parameters and may also include auxiliary values like initial momentum.\n",
        "\n",
        "opt_update is a pytree with the same structure as the `opt_state` argument representing the updated optimizer state.\n",
        "\n",
        "get_params is as well a pytree representing the parameters extracted from `opt_state`, such that the invariant `params == get_params(init_fun(params))` holds true.\n",
        "\n",
        "Basically, a method opt_init that takes in a set of initial parameter values returned by init_fun and returns the initial optimizer state opt_state. Method opt_update takes in gradients and parameters and updates the optimizer states by applying one step of optimization, and a method get_params than takes in an optimizer state and return current parameter values."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "learning_rate = 0.14\n",
        "opt_init, opt_update, get_params = optimizers.sgd(learning_rate)\n",
        "\n",
        "def update(_, i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)"
      ],
      "attachments":{
        
      },
      "execution_count":13,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Next, we will train our model on the training examples. At the end of the training, we will obtain the â€˜paramsâ€™ which we are going to use to calculate the gradient of our loss function w.r.t. the test image."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# definitions\n",
        "num_epochs = 1\n",
        "key = random.PRNGKey(123)\n",
        "_, init_params = init_random_params(key, (-1, 28, 28, 1))"
      ],
      "attachments":{
        
      },
      "execution_count":14,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# training part\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "for i in range(num_batches):\n",
        "  if i % 25 == 0: print('Computing batch {:}\/{:}'.format(i, num_batches))\n",
        "  opt_state= update(key, next(itercount), opt_state, shape_as_image(*next(batches)))\n",
        "\n",
        "params = get_params(opt_state)\n",
        "print(\"Finished\")"
      ],
      "attachments":{
        
      },
      "execution_count":15,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Computing batch 0\/469\n",
            "Computing batch 25\/469\n",
            "Computing batch 50\/469\n",
            "Computing batch 75\/469\n",
            "Computing batch 100\/469\n",
            "Computing batch 125\/469\n",
            "Computing batch 150\/469\n",
            "Computing batch 175\/469\n",
            "Computing batch 200\/469\n",
            "Computing batch 225\/469\n",
            "Computing batch 250\/469\n",
            "Computing batch 275\/469\n",
            "Computing batch 300\/469\n",
            "Computing batch 325\/469\n",
            "Computing batch 350\/469\n",
            "Computing batch 375\/469\n",
            "Computing batch 400\/469\n",
            "Computing batch 425\/469\n",
            "Computing batch 450\/469\n",
            "Finished\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We define the function which will return us the gradient of the loss function w.r.t the test input. This function will calculate test loss as well as predict the class of our target variable. \n",
        "\n",
        "This is pretty straightforward. First line calculates test accuracy. Second line calculates test loss. Third lines calculates the gradients, which are also returned."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def covnet(user_run, params):\n",
        "  # user_run: this function was executed by user and it will print additional information.\n",
        "  test_acc,target_class, predicted_class = accuracy(params, shape_as_image(test_images, test_labels))\n",
        "  test_loss = loss(params, shape_as_image(test_images, test_labels), test=user_run)\n",
        "  grads = grad(lo)(shape_as_image(test_images, test_labels), params)\n",
        "\n",
        "  if user_run == 1:\n",
        "      print('Test accuracy (%): {:.2f}'.format(100 * test_acc))\n",
        "      print('Test loss (%): {:.2f}'.format(test_loss))\n",
        "      print('Predicted class: ', predicted_class)\n",
        "      print('Target class:', target_class)\n",
        "  return grads, test_acc"
      ],
      "attachments":{
        
      },
      "execution_count":16,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# We are near the end. We choose an image which belongs to the class â€˜8â€™ and display it."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "selected_image = 333\n",
        "\n",
        "# Function to display image\n",
        "def display(image):\n",
        "  img = image.reshape((28,28))\n",
        "  plt.imshow(img, cmap=\"Greys\")\n",
        "  plt.show()\n",
        "  return\n",
        "\n",
        "display(train_images[selected_image])"
      ],
      "attachments":{
        
      },
      "execution_count":17,
      "outputs":[
        {
          "data":{
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              "width":0,
              "height":0
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "In next cell, we load the image and test, what are model predicts. If we did everything right, predicted class should be '8'. Bear in mind, that we are testing an image, which the model was trained on, but for our purpose, it does not matter."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def load_img(image,img_label):\n",
        "  img = np.array(image)\n",
        "  img = img.reshape(1,784)\n",
        "  label = np.array(img_label)\n",
        "  label = label.reshape(1,10)\n",
        "  return img, label\n",
        "\n",
        "img, label = load_img(train_images[selected_image],train_labels[selected_image])  \n",
        "test_images = img\n",
        "test_labels = label\n",
        "\n",
        "# predictions before pertubation \n",
        "grads, acc = covnet(1, params)"
      ],
      "attachments":{
        
      },
      "execution_count":18,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Prediction vector before softmax\n",
            "[[ 3.387504   -4.2424345   5.5979037  -0.44558826 -4.4707594   2.9573107\n",
            "   3.8999696  -4.927149   18.507484    0.27495083]]\n",
            "____________________________________________________________________________________\n",
            "Prediction vector after softmax\n",
            "[[-1.5119983e+01 -2.2749924e+01 -1.2909583e+01 -1.8953077e+01\n",
            "  -2.2978249e+01 -1.5550177e+01 -1.4607518e+01 -2.3434637e+01\n",
            "  -3.3378547e-06 -1.8232538e+01]]\n",
            "____________________________________________________________________________________\n",
            "Test accuracy (%): 100.00\n",
            "Test loss (%): 0.00\n",
            "Predicted class:  [8]\n",
            "Target class: [8]\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Letâ€™s perturb the same image with fast gradient sign method. For this purpose, we have defined the function bellow. Here we are using 0.3 as the value of epsilon. Additionaly, lets display the image."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "epsilon = 0.3\n",
        "\n",
        "def perturb(grad, img, epsilon):\n",
        "  grads = grad[0]\n",
        "  a = numpy.reshape(grads, (1, 784))\n",
        "  s = np.sign(a)\n",
        "  perturbed_image = img + np.dot(epsilon,s)\n",
        "  return perturbed_image\n",
        "\n",
        "adversarial_img = perturb(grads, train_images[selected_image], epsilon)\n",
        "display(adversarial_img)"
      ],
      "attachments":{
        
      },
      "execution_count":19,
      "outputs":[
        {
          "data":{
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              "width":0,
              "height":0
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "And the last step, show that are perturbed \/ adversarial image is clearly of class '8', but our neural network is showing class '2'. \n",
        "\n",
        "This approach is applicable also to a more complex datasets than MNIST."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "img, label = load_img(adversarial_img, train_labels[selected_image])  \n",
        "test_images = img\n",
        "test_labels = label\n",
        "\n",
        "grads, acc = covnet(1,params)"
      ],
      "attachments":{
        
      },
      "execution_count":20,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Prediction vector before softmax\n",
            "[[ 1.3961667 -1.5118341 10.725666  -1.465681  -1.659752  -3.4278665\n",
            "   2.1676345  3.5835493  4.9841194 -0.6741743]]\n",
            "____________________________________________________________________________________\n",
            "Prediction vector after softmax\n",
            "[[-9.3337975e+00 -1.2241798e+01 -4.2984951e-03 -1.2195645e+01\n",
            "  -1.2389716e+01 -1.4157830e+01 -8.5623293e+00 -7.1464152e+00\n",
            "  -5.7458453e+00 -1.1404139e+01]]\n",
            "____________________________________________________________________________________\n",
            "Test accuracy (%): 0.00\n",
            "Test loss (%): 5.75\n",
            "Predicted class:  [2]\n",
            "Target class: [8]\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}